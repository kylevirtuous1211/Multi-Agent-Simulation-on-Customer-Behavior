import os
import openai
import json
import requests
from bs4 import BeautifulSoup
import asyncio
from typing import List
from googlesearch import search as _search
from requests_html import AsyncHTMLSession
from bs4 import BeautifulSoup
from charset_normalizer import from_bytes

base_url = "https://api.groq.com/openai/v1"
api_key = os.environ.get("API_KEY")
client = openai.OpenAI(api_key=api_key, base_url=base_url)
model = "gemma2-9b-it"

tools = [
    {
        "type": "function",
        "function": {
            "name": "web_search_agent",
            "description": "æœå°‹ç¶²é ä¸¦å›å‚³ç´”æ–‡å­—å…§å®¹",
            "parameters": {
                "type": "object",
                "properties": {
                    "keyword": {"type": "string"},
                    "n_results": {"type": "integer", "default": 1}
                },
                "required": ["keyword"]
            }
        }
    }
]

# -------- ç¶²é æŠ“å– Worker --------
async def worker(s: AsyncHTMLSession, url: str) -> str | None:
    try:
        # å…ˆçœ‹ headers ç¢ºä¿æ˜¯ HTML é é¢
        header_response = await asyncio.wait_for(s.head(url, verify=True), timeout=10)
        if 'text/html' not in header_response.headers.get('Content-Type', ''):
            return None
        
        # æŠ“å–å®Œæ•´ HTML é é¢
        response = await asyncio.wait_for(s.get(url, verify=True), timeout=10)
        return response.content.decode(response.encoding or 'utf-8', errors='ignore')

    except Exception as e:
        print(f"[Error] ç„¡æ³•æŠ“å– {url}ï¼š{e}")
        return None

# -------- æ‰¹æ¬¡æŠ“å–ç¶²é  HTML --------
async def get_htmls(urls: List[str]) -> List[str]:
    session = AsyncHTMLSession()
    tasks = [worker(session, url) for url in urls]
    return await asyncio.gather(*tasks)

# -------- ä¸»æœå°‹ Agent --------
async def web_search_agent(keyword: str, n_results: int = 1) -> List[str]:
    '''
    éåŒæ­¥ç¶²é æœå°‹èˆ‡æ¸…æ´—æ–‡å­—ï¼Œé©ç”¨æ–¼ç‰¹å¾µèƒå–æˆ–èªæ„åˆ†æã€‚
    '''
    keyword = keyword[:100]
    urls = list(_search(keyword, num_results=n_results * 2, lang="zh", unique=True))
    htmls = await get_htmls(urls)
    htmls = [x for x in htmls if x is not None]

    results = []
    for html in htmls:
        try:
            encoding = from_bytes(html.encode()).best().encoding
            soup = BeautifulSoup(html, 'html.parser')
            text = soup.get_text(separator=' ', strip=True)
            results.append(''.join(text.split()))
        except Exception as e:
            continue

    return results[:n_results]

# prompt template
def build_prompt(feature: str) -> str:
    return f"""
    ä½ æ˜¯ä¸€ä½ç”¢å“ç¶“ç†åŠ©ç†ï¼Œè«‹ä½¿ç”¨ RICE æ¨¡å‹ç‚ºä¸‹åˆ— feature åšè©•ä¼°ï¼Œä¸¦çµ¦å‡ºæ¯ä¸€é …æŒ‡æ¨™ï¼ˆ1-5 åˆ†ï¼‰èˆ‡ç†ç”±ï¼Œæœ€å¾Œè¨ˆç®— priority åˆ†æ•¸ã€‚

    è«‹ä¾ä»¥ä¸‹æ ¼å¼å›è¦†ï¼š
    Feature: <æè¿°>
    Reach: <1-5 åˆ† + ç†ç”±>
    Impact: <1-5 åˆ† + ç†ç”±>
    Confidence: <1-5 åˆ† + ç†ç”±>
    Effort: <1-5 åˆ† + ç†ç”±>
    Priority Score: <è¨ˆç®—å€¼ï¼šReach x Impact x Confidence / Effort>
    Reason Summary: <ç¶œåˆæ’åºä¾æ“š>

    Feature: {feature}
    """

# å‘¼å« GPT æ¨¡å‹åˆ†ææ¯å€‹ feature
def analyze_feature(feature: str) -> dict:
    prompt = build_prompt(feature)

    response = client.chat.completions.create(
        model=model,
        temperature=0.3,
        tools=tools,
        tool_choice="auto",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ç”¢å“ç¶“ç†åŠ©ç†ï¼Œç†Ÿæ‚‰ feature è©•ä¼°èˆ‡ RICE æ¨¡å‹ã€‚"},
            {"role": "user", "content": prompt}
        ]
    )

    message = response.choices[0].message
    tool_calls = message.tool_calls

    if tool_calls:
        for tool_call in tool_calls:
            function_name = tool_call.function.name
            arguments = json.loads(tool_call.function.arguments)
            
            print("arguments:", arguments)

            if function_name == "web_search_agent":
                loop = asyncio.get_event_loop()
                result = loop.run_until_complete(web_search_agent(**arguments))
                
            print(len("\n".join(result)))
            # å†åŒ…æˆå·¥å…·çš„å›æ‡‰è¨Šæ¯
            tool_response_message = {
                "role": "tool",
                "tool_call_id": tool_call.id,
                "content": "\n".join(result)[0:min(1024,len("\n".join(result)))]  # â¬…ï¸ é€™æ˜¯ä½ çš„å·¥å…·å›å‚³çš„å…§å®¹
                # "content": "\n".join(map(str, result)) if isinstance(result, list) else str(result)
            }

            # ä¸Ÿå› GPT åšä¸‹ä¸€æ­¥æ¨ç†
            second_response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ç”¢å“ç¶“ç†åŠ©ç†ï¼Œç†Ÿæ‚‰ feature è©•ä¼°èˆ‡ RICE æ¨¡å‹ã€‚"},
                    {"role": "user", "content": prompt},
                    {
                        "role": "assistant",
                        "tool_calls": [tool_call]  # å‘¼å«ç´€éŒ„
                    },
                    tool_response_message
                ]
            )

            # print("\nğŸŸ¢ GPT å›æ‡‰ï¼š")
            # print(second_response.choices[0].message.content)

    return second_response.choices[0].message.content