{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87dec124",
   "metadata": {},
   "source": [
    "## 搜尋網路 Function\n",
    "1. 過濾網域：先在台灣的網域 (用fstring加上`.tw`)\n",
    "\n",
    "EX:`\n",
    "search_web(\"空氣清淨機 使用心得\", site=\"ptt.cc\")\n",
    "search_web(\"Switch 遊戲 評價\", site=\"shopee.tw\")\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b5fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import GoogleSearch\n",
    "\n",
    "def search_web(query, site=None, lang='zh-TW', num=100):\n",
    "    if site:\n",
    "        query = f\"{query} site:{site}\"\n",
    "    else:\n",
    "        query = f\"{query} site:.tw\"\n",
    "\n",
    "    all_results = []\n",
    "    for start in range(0, num, 10):\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"api_key\": \"YOUR_SERPAPI_KEY\",\n",
    "            \"lr\": lang,\n",
    "            \"hl\": \"zh-tw\",  # 介面語言\n",
    "            \"gl\": \"tw\",    # 地理位置\n",
    "            \"start\": start\n",
    "        }\n",
    "        search = GoogleSearch(params)\n",
    "        results = search.get_dict()\n",
    "\n",
    "        organic = results.get(\"organic_results\", [])\n",
    "        all_results.extend([\n",
    "            {\n",
    "                \"title\": r.get(\"title\", \"\"),\n",
    "                \"link\": r.get(\"link\", \"\"),\n",
    "                \"snippet\": r.get(\"snippet\", \"\")\n",
    "            }\n",
    "            for r in organic if 'snippet' in r\n",
    "        ])\n",
    "    \n",
    "    return all_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714f0bad",
   "metadata": {},
   "source": [
    "1. 用`jieba`產生中文token\n",
    "2. 移除攏言贅字 (`stopwords`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7252959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from collections import Counter\n",
    "\n",
    "# Optional: Define your own Chinese stopwords\n",
    "stopwords = set([\n",
    "    \"的\", \"是\", \"我\", \"也\", \"很\", \"都\", \"在\", \"有\", \"和\", \"就\", \"不\", \"了\", \"還\", \"這\", \"好\"\n",
    "])\n",
    "\n",
    "def extract_frequent_keywords(snippets, top_k=20):\n",
    "    # Combine all snippets\n",
    "    all_text = \" \".join(snippets)\n",
    "\n",
    "    # Use jieba to cut Chinese text into words\n",
    "    words = jieba.cut(all_text)\n",
    "\n",
    "    # Filter out stopwords and short tokens\n",
    "    filtered_words = [w for w in words if w not in stopwords and len(w.strip()) > 1]\n",
    "\n",
    "    # Count frequency\n",
    "    word_counts = Counter(filtered_words)\n",
    "\n",
    "    return word_counts.most_common(top_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80955cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "snippets = \n",
    "top_keywords = extract_frequent_keywords(snippets)\n",
    "for word, freq in top_keywords:\n",
    "    print(f\"{word}: {freq}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
