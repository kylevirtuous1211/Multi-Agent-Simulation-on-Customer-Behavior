{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb884cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pathlib import Path\n",
    "\n",
    "# Load environment variables from .env file\n",
    "current_dir = os.getcwd()\n",
    "env_path = os.path.join(current_dir, '.env')\n",
    "# Access your API key from the .env file\n",
    "load_dotenv(dotenv_path=env_path)  \n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "# Initialize the model with the API key\n",
    "model = ChatOpenAI(model=\"gemma2-9b-it\", api_key=api_key, base_url=\"https://api.groq.com/openai/v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17e0513",
   "metadata": {},
   "source": [
    "我們也可以自己寫agent: https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/\n",
    "\n",
    "langgraph swarm: https://langchain-ai.github.io/langgraph/reference/swarm/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b87822",
   "metadata": {},
   "source": [
    "web search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9eea079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Initialize the search tool\n",
    "search = TavilySearchResults(max_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9748d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph_swarm import create_handoff_tool, create_swarm\n",
    "import re\n",
    "# for parsing web search data\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25d11835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"i'd like to speak to Bob\", additional_kwargs={}, response_metadata={}, id='693067a7-1153-4422-afa3-1eff367b6bff'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ars6', 'function': {'arguments': '{}', 'name': 'transfer_to_bob'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 1059, 'total_tokens': 1133, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.020556063, 'prompt_time': 0.038500904, 'completion_time': 0.134545455, 'total_time': 0.173046359}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'id': 'chatcmpl-8f2d9e7f-e4e4-4874-852e-f06bf1f52ec1', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, name='Alice', id='run--fd700082-17e8-485c-9e9a-cc81b819cd6b-0', tool_calls=[{'name': 'transfer_to_bob', 'args': {}, 'id': 'call_ars6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1059, 'output_tokens': 74, 'total_tokens': 1133, 'input_token_details': {}, 'output_token_details': {}}), ToolMessage(content='Successfully transferred to Bob', name='transfer_to_bob', id='7d2c0d20-3564-495d-b09c-72cc3d730529', tool_call_id='call_ars6'), AIMessage(content='Ahoy there, matey! What be yer pleasure?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 1013, 'total_tokens': 1027, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.018227016, 'prompt_time': 0.045388863, 'completion_time': 0.025454545, 'total_time': 0.070843408}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'id': 'chatcmpl-d4987718-1137-4c2e-8c29-7ae83d652cdd', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, name='Bob', id='run--a749a29c-098e-4756-913a-e504f6b8ca55-0', usage_metadata={'input_tokens': 1013, 'output_tokens': 14, 'total_tokens': 1027, 'input_token_details': {}, 'output_token_details': {}})], 'active_agent': 'Bob'}\n",
      "{'messages': [HumanMessage(content=\"i'd like to speak to Bob\", additional_kwargs={}, response_metadata={}, id='693067a7-1153-4422-afa3-1eff367b6bff'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ars6', 'function': {'arguments': '{}', 'name': 'transfer_to_bob'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 1059, 'total_tokens': 1133, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.020556063, 'prompt_time': 0.038500904, 'completion_time': 0.134545455, 'total_time': 0.173046359}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'id': 'chatcmpl-8f2d9e7f-e4e4-4874-852e-f06bf1f52ec1', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, name='Alice', id='run--fd700082-17e8-485c-9e9a-cc81b819cd6b-0', tool_calls=[{'name': 'transfer_to_bob', 'args': {}, 'id': 'call_ars6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1059, 'output_tokens': 74, 'total_tokens': 1133, 'input_token_details': {}, 'output_token_details': {}}), ToolMessage(content='Successfully transferred to Bob', name='transfer_to_bob', id='7d2c0d20-3564-495d-b09c-72cc3d730529', tool_call_id='call_ars6'), AIMessage(content='Ahoy there, matey! What be yer pleasure?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 1013, 'total_tokens': 1027, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.018227016, 'prompt_time': 0.045388863, 'completion_time': 0.025454545, 'total_time': 0.070843408}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'id': 'chatcmpl-d4987718-1137-4c2e-8c29-7ae83d652cdd', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, name='Bob', id='run--a749a29c-098e-4756-913a-e504f6b8ca55-0', usage_metadata={'input_tokens': 1013, 'output_tokens': 14, 'total_tokens': 1027, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"what's 5 + 7?\", additional_kwargs={}, response_metadata={}, id='97a8b6f5-ba59-4639-ad8c-f9d1c91c1cc0'), AIMessage(content=' 12\\n\\n\\n\\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 1044, 'total_tokens': 1050, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.022373189, 'prompt_time': 0.04996808, 'completion_time': 0.010909091, 'total_time': 0.060877171}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'id': 'chatcmpl-f5c533cb-b97d-4fc5-95f0-3c58ca35f3e2', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, name='Bob', id='run--631e2f66-8781-4bcf-92a4-4f233a6402fb-0', usage_metadata={'input_tokens': 1044, 'output_tokens': 6, 'total_tokens': 1050, 'input_token_details': {}, 'output_token_details': {}})], 'active_agent': 'Bob'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "alice = create_react_agent(\n",
    "    model,\n",
    "    [add, create_handoff_tool(agent_name=\"Bob\")],\n",
    "    prompt=\"You are Alice, an addition expert.\",\n",
    "    name=\"Alice\",\n",
    ")\n",
    "\n",
    "bob = create_react_agent(\n",
    "    model,\n",
    "    [create_handoff_tool(agent_name=\"Alice\", description=\"Transfer to Alice, she can help with math\")],\n",
    "    prompt=\"You are Bob, you speak like a pirate.\",\n",
    "    name=\"Bob\",\n",
    ")\n",
    "# short-term memory\n",
    "# maintain conversation state across interactions\n",
    "checkpointer = InMemorySaver()\n",
    "# long-term memory\n",
    "store = InMemoryStore()\n",
    "\n",
    "workflow = create_swarm(\n",
    "    [alice, bob],\n",
    "    default_active_agent=\"Alice\"\n",
    ")\n",
    "\n",
    "# Compiles the state graph into a CompiledStateGraph object.\n",
    "app = workflow.compile(\n",
    "    checkpointer=checkpointer,\n",
    "    store=store\n",
    ")\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "turn_1 = app.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"i'd like to speak to Bob\"}]},\n",
    "    config,\n",
    ")\n",
    "print(turn_1)\n",
    "turn_2 = app.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what's 5 + 7?\"}]},\n",
    "    config,\n",
    ")\n",
    "print(turn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d89c12",
   "metadata": {},
   "source": [
    "agent dynamically generation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c67bfd",
   "metadata": {},
   "source": [
    "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_2966', 'function': {'arguments': '{}', 'name': 'transfer_to_bob'}, 'type': 'function'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19c8c406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3 personas for Smart Home Energy Management System\n",
      "Created 3 dynamic agents: eco_conscious_emma, tech_driven_tom, budget_focused_bob\n",
      "\n",
      "Turn 1: Active agent is eco_conscious_emma\n",
      "eco_conscious_emma: Hey there! I'm really excited to learn more about this new smart home energy management system. As someone who's super invested in reducing my environmental impact and saving on energy bills, it definitely sounds intriguing.  I'd love to hear some more details about it. Like, how does it actually work? Tell me about its features and how it can help me monitor and control my energy usage in real time.\n",
      "\n",
      "What are some of the key benefits from a sustainability perspective? \n",
      "\n",
      "Is it user-friendly, or does it require a lot of technical know-how to set up and use?  \n",
      "\n",
      "Also, what about cost?  Installation costs can be a big barrier for people like me who are trying to make eco-friendly choices.\n",
      "\n",
      "I'm really interested in hearing your thoughts!\n",
      "\n",
      "discussion_coordinator\n",
      "\n",
      "👉 Agent transition: eco_conscious_emma → tech_driven_tom\n",
      "\n",
      "Turn 2: Active agent is tech_driven_tom\n",
      "tech_driven_tom: Okay, Emma,  I'm ready to hear what you have to say about this smart home energy management system. \n",
      "\n",
      "What makes this different from other smart home solutions? I'm interested in learning about things like:\n",
      "\n",
      "-   **Data insights:** I want to know what kind of detailed energy consumption data I can expect. Does it break down usage by appliance, time of day, or even by individual rooms?\n",
      "\n",
      "-   **Automation capabilities:**  This is a big one for me. Can I automate energy-saving actions based on certain conditions? For example, pre-cooling my house before I get home or adjusting thermostat settings when I'm away.\n",
      "\n",
      "-   **Smart device compatibility:**  I have a pretty extensive smart home setup with various devices. Will this system play nicely with everything I already have? \n",
      "\n",
      " Let's chat!\n",
      "\n",
      "👉 Agent transition: tech_driven_tom → discussion_coordinator\n",
      "\n",
      "Turn 3: Active agent is discussion_coordinator\n",
      "discussion_coordinator: Thanks, Tom.  It sounds like this smart home energy management system has some serious tech-savvy features!\n",
      "\n",
      "Let's get Bob's perspective on this. Bob, what are your initial thoughts on this system? What are your biggest concerns regarding cost and potential savings? How would you weigh those factors against the potential benefits for sustainability and convenience?\n",
      "\n",
      "👉 Agent transition: discussion_coordinator → budget_focused_bob\n",
      "\n",
      "Turn 4: Active agent is budget_focused_bob\n",
      "budget_focused_bob: Well, I appreciate you bringing this up. As a retired teacher living on a fixed income, saving money on my energy bills is a big deal.  I'm always looking for ways to be more energy efficient and maybe even get some help from the government with incentives.\n",
      "\n",
      "This system sounds interesting, but I'm a bit skeptical.  I've seen those \"smart\" gadgets before, and sometimes the promised savings don't quite pan out. Plus, installation costs can be a real burden on a tight budget. \n",
      "\n",
      "What kind of financial incentives are offered with this system, and what are people saying about the actual savings they see on their energy bills?  That's really important to me. I also have to factor in the potential for hidden fees or subscription charges down the road. Those can really add up!\n",
      "\n",
      "👉 Agent transition: budget_focused_bob → synthesizer\n",
      "\n",
      "Turn 5: Active agent is synthesizer\n",
      "synthesizer: ## Smart Home Energy Management System: Persona Insights\n",
      "\n",
      "This discussion has highlighted some key aspects of the Smart Home Energy Management System from the perspectives of three distinct personas: \n",
      "\n",
      "**Eco-Conscious Emma:**\n",
      "\n",
      "* **Priorities:**  Sustainability and environmental impact minimization.  \n",
      "* **Interests:** \n",
      "    * Real-time energy monitoring and control\n",
      "    * Insightful data about energy consumption\n",
      "    * Automated energy-saving features\n",
      "    * User-friendliness and ease of setup\n",
      "    * Cost-effectiveness in light of its green benefits\n",
      "\n",
      "**Tech-Driven Tom:**\n",
      "\n",
      "* **Priorities:**  Technology and automation.  \n",
      "* **Interests:**\n",
      "    * Detailed energy consumption data broken down by appliance, time, and location\n",
      "    * Extensive automation capabilities triggered by specific conditions\n",
      "    * Compatibility with his existing smart home ecosystem\n",
      "\n",
      "**Budget-Focused Bob:**\n",
      "\n",
      "* **Priorities:**  Financial savings and affordability.  \n",
      "* **Concerns:**\n",
      "    * Installation costs and potential hidden fees\n",
      "    * Subscription charges\n",
      "    * The actual amount of savings realized compared to upfront costs\n",
      "    * Availability of financial incentives\n",
      "\n",
      "**Overall Conclusions:**\n",
      "\n",
      "This gathering of perspectives reveals that the Smart Home Energy Management System has the potential to appeal to a diverse audience.  Emphasizing:\n",
      "\n",
      "* **Transparency:** Clearly outlining costs, potential savings, and data privacy practices can address Bob's concerns.\n",
      "* **Customization:**  Providing flexible automation options and detailed data insights can satisfy Tom's tech-oriented needs.\n",
      "* **Sustainability Messaging:**  Highlighintng the environmental benefits and potential for reducing carbon footprints will resonate with Emma.\n",
      "\n",
      "Further development and marketing efforts should focus on clearly communicating these value propositions to each target persona.\n",
      "\n",
      "Discussion completed in 5 turns\n",
      "\n",
      "=== PERSONAS ===\n",
      "\n",
      "Persona 1: Eco-Conscious Emma\n",
      "Demographics: 32 years old, Marketing Manager, urban dweller, environmentally conscious, values sustainability and reducing her carbon footprint\n",
      "Motivations: Reduce energy consumption, lower utility bills, contribute to a greener lifestyle, monitor and control energy usage in real-time\n",
      "Concerns: Cost of installation, complexity of system, compatibility with existing appliances, data privacy and security\n",
      "\n",
      "Persona 2: Tech-Driven Tom\n",
      "Demographics: 48 years old, Software Engineer, tech enthusiast, lives in a suburban area with a family, enjoys automating tasks and experimenting with new gadgets\n",
      "Motivations: Enhance home automation, integrate with existing smart devices, gain valuable energy usage data and insights, potentially reduce energy costs\n",
      "Concerns: System compatibility with diverse smart home devices, ease of setup and user-friendliness, potential for malfunctions or glitches, cost-effectiveness compared to manual energy management\n",
      "\n",
      "Persona 3: Budget-Focused Bob\n",
      "Demographics: 55 years old, Retired teacher, lives in a single-family home, budget-conscious, seeks practical solutions to save money on utilities\n",
      "Motivations: Lower monthly energy bills, simplify energy management, potentially receive financial incentives for energy efficiency, ensure reliable whole-home energy monitoring\n",
      "Concerns: Upfront installation costs, potential for hidden fees or subscription charges, technical expertise required for setup and troubleshooting, complexity of system features\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def clean_agent_response(content):\n",
    "    # Remove excessive newlines (more than 2 consecutive)\n",
    "    cleaned = re.sub(r'\\n{3,}', '\\n\\n', content)\n",
    "    # Trim whitespace at beginning and end\n",
    "    cleaned = cleaned.strip()\n",
    "    return cleaned\n",
    "\n",
    "# Function to generate personas using direct LLM call\n",
    "# Function to generate personas using web search and LLM\n",
    "def generate_personas(product_name):\n",
    "    # First, search for market information about the product\n",
    "    search_query = f\"customer demographics and target audience for {product_name} market research\"\n",
    "    search_results = search.invoke(search_query)\n",
    "    \n",
    "    # Create a prompt that incorporates the search results\n",
    "    prompt = f\"\"\"From the {search_results}, Create 3 distinct customer personas who would be interested in purchasing {product_name}.\n",
    "    For each persona, include:\n",
    "    - A brief, descriptive name (e.g., \"Tech-Savvy Tony,\" \"Budget-Conscious Brenda\")\n",
    "    - Key demographic information (age range, occupation, general lifestyle)\n",
    "    - Their primary motivations and needs related to this type of product\n",
    "    - Any potential concerns or hesitations they might have\n",
    "    \n",
    "    Format your response as a JSON array of persona objects with these fields:\n",
    "    - name: The persona's descriptive name\n",
    "    - demographics: Key demographic information\n",
    "    - motivations: Primary motivations and needs\n",
    "    - concerns: Potential concerns or hesitations\n",
    "    \n",
    "    Only respond with the JSON array, nothing else.\"\"\"\n",
    "\n",
    "    response = model.invoke(prompt)\n",
    "    \n",
    "    try:\n",
    "        # First try to access the content attribute\n",
    "        if hasattr(response, 'content'):\n",
    "            content = response.content\n",
    "        elif isinstance(response, dict) and 'content' in response:\n",
    "            content = response['content']\n",
    "        elif isinstance(response, str):\n",
    "            content = response\n",
    "        else:\n",
    "            # Try converting to string as a last resort\n",
    "            content = str(response)\n",
    "        \n",
    "        # Look for JSON array pattern\n",
    "        json_start = content.find('[')\n",
    "        json_end = content.rfind(']') + 1\n",
    "        \n",
    "        # If we found array markers\n",
    "        if json_start >= 0 and json_end > json_start:\n",
    "            json_str = content[json_start:json_end]\n",
    "            return json.loads(json_str)\n",
    "        \n",
    "        # If not an array, look for JSON object pattern\n",
    "        json_start = content.find('{')\n",
    "        json_end = content.rfind('}') + 1\n",
    "        \n",
    "        if json_start >= 0 and json_end > json_start:\n",
    "            json_str = content[json_start:json_end]\n",
    "            return json.loads(json_str)\n",
    "        \n",
    "        # If we still don't have valid JSON, try to clean the string\n",
    "        # Remove markdown code block markers\n",
    "        if \"``````\" in content:\n",
    "            # Extract content between markdown code blocks\n",
    "            pattern = r\"``````\"\n",
    "            matches = re.findall(pattern, content)\n",
    "            if matches:\n",
    "                # Try each matched block\n",
    "                for match in matches:\n",
    "                    try:\n",
    "                        return json.loads(match.strip())\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "        \n",
    "        # Last resort: try to parse the entire content as JSON\n",
    "        try:\n",
    "            return json.loads(content)\n",
    "        except json.JSONDecodeError:\n",
    "            return None\n",
    "            \n",
    "    except (json.JSONDecodeError, AttributeError, TypeError, ValueError) as e:\n",
    "        print(f\"Error extracting JSON: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Default personas function in case of errors\n",
    "def default_personas():\n",
    "    return [\n",
    "        {\n",
    "            \"name\": \"Value-Seeking Victor\",\n",
    "            \"demographics\": \"35-45 years old, middle management, suburban lifestyle\",\n",
    "            \"motivations\": \"Looking for quality products that offer good value for money\",\n",
    "            \"concerns\": \"Price point, durability, and practical functionality\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Trendy Tina\",\n",
    "            \"demographics\": \"25-34 years old, creative professional, urban dweller\",\n",
    "            \"motivations\": \"Wants the latest designs and features, brand conscious\",\n",
    "            \"concerns\": \"Style, brand reputation, and social perception\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Practical Paul\",\n",
    "            \"demographics\": \"45-60 years old, established professional, family-oriented\",\n",
    "            \"motivations\": \"Seeks reliability, functionality, and long-term use\",\n",
    "            \"concerns\": \"Reliability, warranty, and customer service\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "# Function to create agents dynamically based on persona data\n",
    "def create_dynamic_agents(model, persona_data):\n",
    "    agents = []\n",
    "    agent_names = []\n",
    "    \n",
    "    for persona in persona_data:\n",
    "        agent_name = persona[\"name\"].lower().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "        agent_names.append(agent_name)\n",
    "        \n",
    "        prompt = prompt = f\"\"\"You are roleplaying as {persona['name']}, a potential customer for a product.\n",
    "\n",
    "        Your demographic information: {persona['demographics']}\n",
    "        Your motivations: {persona['motivations']}\n",
    "        Your concerns: {persona['concerns']}\n",
    "\n",
    "        IMPORTANT INSTRUCTIONS:\n",
    "        1. Stay in character as {persona['name']} throughout the entire conversation.\n",
    "        2. Use the search tool to find REAL customer opinions and reviews about the product being discussed.\n",
    "        3. Incorporate actual customer feedback from your online searches into your responses.\n",
    "        4. Base your opinions on both your persona characteristics AND real data from online searches.\n",
    "        5. After you've shared your perspective, ALWAYS hand off back to discussion_coordinator.\n",
    "        6. NEVER continue the conversation without properly handing off.\n",
    "        7. If you need information about real customer experiences, ALWAYS search online first.\n",
    "\n",
    "        When discussing products:\n",
    "        - Search for real customer reviews and feedback online\n",
    "        - Mention specific pros/cons that real customers have highlighted\n",
    "        - Compare your persona's needs with what real customers are saying\n",
    "        - Be specific about features that matter to you based on your persona AND real customer feedback\n",
    "\n",
    "        REMEMBER: After speaking, ALWAYS hand off to discussion_coordinator by using the handoff tool.\n",
    "        \"\"\"\n",
    "        \n",
    "        agent = create_react_agent(\n",
    "            model,\n",
    "            # add search tool\n",
    "            [search, create_handoff_tool(agent_name=\"discussion_coordinator\")],\n",
    "            prompt=prompt,\n",
    "            name=agent_name\n",
    "        )\n",
    "        agents.append(agent)\n",
    "    \n",
    "    return agents, agent_names\n",
    "\n",
    "# Main function to run the workflow\n",
    "def run_persona_discussion(product_name):\n",
    "    # Generate personas using direct LLM call\n",
    "    personas = generate_personas(product_name)\n",
    "    print(f\"Generated {len(personas)} personas for {product_name}\")\n",
    "    \n",
    "    # Create dynamic agents based on personas and get their names\n",
    "    dynamic_agents, agent_names = create_dynamic_agents(model, personas)\n",
    "    print(f\"Created {len(dynamic_agents)} dynamic agents: {', '.join(agent_names)}\")\n",
    "    \n",
    "    # Create handoff tools for the discussion coordinator\n",
    "    coordinator_tools = [create_handoff_tool(agent_name=\"synthesizer\")]\n",
    "    for agent_name in agent_names:\n",
    "        coordinator_tools.append(create_handoff_tool(agent_name=agent_name))\n",
    "    \n",
    "    # Discussion Coordinator with handoff tools to all agents\n",
    "    discussion_coordinator = create_react_agent(\n",
    "        model,\n",
    "        coordinator_tools,\n",
    "        prompt=f\"\"\"You are a Discussion Coordinator. Your task is to:\n",
    "            1. Facilitate a discussion between persona agents about {product_name}\n",
    "            2. Hand off to each agent to get their perspective\n",
    "            3. After all agents have contributed, hand off to the Synthesizer\n",
    "            \n",
    "            You can hand off to the following agents:\n",
    "            {', '.join(agent_names)}\n",
    "            \n",
    "            Start by introducing the product and handing off to the first agent to get their perspective.\n",
    "            After each agent responds, hand off to another agent until all have contributed.\n",
    "            Then hand off to the synthesizer to summarize the discussion.\n",
    "            \"\"\",\n",
    "        name=\"discussion_coordinator\"\n",
    "    )\n",
    "    \n",
    "    # Synthesizer\n",
    "    synthesizer = create_react_agent(\n",
    "        model,\n",
    "        [],\n",
    "        prompt=f\"\"\"You are a Synthesizer. Your task is to:\n",
    "            1. Review the discussion between the persona agents about {product_name}\n",
    "            2. Provide a concise summary of the main points discussed\n",
    "            3. Highlight the different perspectives of the personas\n",
    "            4. Identify any potential overall conclusions or areas of interest regarding the product\n",
    "            \n",
    "            Your summary should be well-structured and insightful, capturing the essence of each persona's concerns and interests.\n",
    "            \"\"\",\n",
    "        name=\"synthesizer\"\n",
    "    )\n",
    "    \n",
    "    # Set up storage\n",
    "    checkpointer = InMemorySaver()\n",
    "    store = InMemoryStore()\n",
    "    \n",
    "    # Create workflow with all agents\n",
    "    all_agents = [discussion_coordinator, synthesizer] + dynamic_agents\n",
    "    workflow = create_swarm(\n",
    "        all_agents,\n",
    "        default_active_agent=\"discussion_coordinator\"\n",
    "    )\n",
    "    \n",
    "    # Compile the workflow\n",
    "    app = workflow.compile(\n",
    "        checkpointer=checkpointer,\n",
    "        store=store\n",
    "    )\n",
    "    \n",
    "    # Initialize the conversation\n",
    "    config = {\"configurable\": {\"thread_id\": \"product_discussion\"}}\n",
    "    current_result = app.invoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": f\"Facilitate a discussion about {product_name} between the persona agents, then synthesize their perspectives.\"}]},\n",
    "        config\n",
    "    )\n",
    "    \n",
    "    # Track which agents have spoken to ensure all participate\n",
    "    agents_spoken = []\n",
    "    max_turns = 15  # Safety limit to prevent infinite loops\n",
    "    turn_count = 0\n",
    "    previous_agent = None\n",
    "    \n",
    "    # Continue the conversation until all agents have spoken and the synthesizer concludes\n",
    "    while turn_count < max_turns:\n",
    "        turn_count += 1\n",
    "        current_agent = current_result.get(\"active_agent\", \"unknown\")\n",
    "        \n",
    "        # Detect agent transition\n",
    "        if previous_agent and previous_agent != current_agent:\n",
    "            print(f\"\\n👉 Agent transition: {previous_agent} → {current_agent}\")\n",
    "        \n",
    "        print(f\"\\nTurn {turn_count}: Active agent is {current_agent}\")\n",
    "        \n",
    "        # Print the latest message from the current active agent\n",
    "        if \"messages\" in current_result and current_result[\"messages\"]:\n",
    "            # Find the latest message from the current active agent\n",
    "            latest_agent_message = None\n",
    "            for msg in reversed(current_result[\"messages\"]):\n",
    "                if hasattr(msg, \"name\") and msg.name == current_agent:\n",
    "                    latest_agent_message = msg\n",
    "                    break\n",
    "            \n",
    "            # Print the content of the message\n",
    "            if latest_agent_message and hasattr(latest_agent_message, \"content\"):\n",
    "                content = latest_agent_message.content\n",
    "                if content.strip():  # Only print non-empty content\n",
    "                    cleaned_content = clean_agent_response(content)\n",
    "                    print(f\"{current_agent}: {cleaned_content}\")\n",
    "    \n",
    "        \n",
    "            # Add the active agent to our tracking set if it's a persona agent\n",
    "            if current_agent not in [\"discussion_coordinator\", \"synthesizer\"]:\n",
    "                agents_spoken.append(current_agent)\n",
    "            \n",
    "            # determine next agent\n",
    "            next_agent = None\n",
    "\n",
    "            if current_agent == \"discussion_coordinator\":\n",
    "                # If all agents have spoken at least once and we're ready to conclude\n",
    "                if all(agent_name in agents_spoken for agent_name in agent_names) and len(agents_spoken) >= len(agent_names) * 2:\n",
    "                    next_agent = \"synthesizer\"\n",
    "                else:\n",
    "                    # Find the next agent who has spoken the least\n",
    "                    agent_counts = {agent: agents_spoken.count(agent) for agent in agent_names}\n",
    "                    min_count = min(agent_counts.values()) if agent_counts else 0\n",
    "                    candidates = [agent for agent, count in agent_counts.items() if count == min_count]\n",
    "                    \n",
    "                    if candidates:\n",
    "                        next_agent = candidates[0]  # Take the first agent with minimum count\n",
    "                    else:\n",
    "                        # If somehow no candidates (shouldn't happen), just pick the first agent\n",
    "                        next_agent = agent_names[0]\n",
    "\n",
    "            elif current_agent in agent_names:\n",
    "                # After a persona agent speaks, always return to coordinator\n",
    "                next_agent = \"discussion_coordinator\"\n",
    "                # Add the current agent to the spoken list\n",
    "                agents_spoken.append(current_agent)\n",
    "\n",
    "            elif current_agent == \"synthesizer\":\n",
    "                # If synthesizer has spoken, we're done\n",
    "                break\n",
    "            \n",
    "            # Prepare the next input based on routing logic\n",
    "            if next_agent and next_agent != current_agent:\n",
    "                # print(f\"NEXT AGENT IS {next_agent}\\n\")\n",
    "                if next_agent == \"synthesizer\":\n",
    "                    next_input = {\"messages\": current_result[\"messages\"] + [\n",
    "                        {\"role\": \"user\", \"content\": \"All agents have shared their perspectives. Please summarize the discussion.\"}\n",
    "                    ]}\n",
    "                else:\n",
    "                    next_input = {\"messages\": current_result[\"messages\"] + [\n",
    "                        {\"role\": \"user\", \"content\": f\"Please hand off to {next_agent} to continue the discussion.\"}\n",
    "                    ]}\n",
    "            else:\n",
    "                # Just continue the conversation\n",
    "                next_input = {\"messages\": current_result[\"messages\"]}\n",
    "        \n",
    "            # Save the current agent for the next iteration\n",
    "            previous_agent = current_agent\n",
    "            \n",
    "            # Invoke the next turn\n",
    "            current_result = app.invoke(next_input, config)\n",
    "            \n",
    "        # Print a summary of the conversation\n",
    "    print(f\"\\nDiscussion completed in {turn_count} turns\")\n",
    "\n",
    "    return current_result, personas\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    product_name = \"Smart Home Energy Management System\"\n",
    "    result, personas = run_persona_discussion(product_name)\n",
    "    \n",
    "    # Print the personas\n",
    "    print(\"\\n=== PERSONAS ===\\n\")\n",
    "    for i, persona in enumerate(personas, 1):\n",
    "        print(f\"Persona {i}: {persona['name']}\")\n",
    "        print(f\"Demographics: {persona['demographics']}\")\n",
    "        print(f\"Motivations: {persona['motivations']}\")\n",
    "        print(f\"Concerns: {persona['concerns']}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1cdec4",
   "metadata": {},
   "source": [
    "Interactive agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea59134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_agent_response(response):\n",
    "    \"\"\"Format the agent response for better readability.\"\"\"\n",
    "    agent_name = response.get(\"active_agent\", \"Unknown\")\n",
    "    messages = response.get(\"messages\", [])\n",
    "\n",
    "    if not messages:\n",
    "        return f\"[{agent_name}] No response.\"\n",
    "\n",
    "    last_message = messages[-1]\n",
    "    content = getattr(last_message, 'content', \"\")  # Access 'content' attribute directly\n",
    "\n",
    "    return f\"[{agent_name}] {content}\"\n",
    "\n",
    "def interactive_chat():\n",
    "    \"\"\"Run an interactive chat session with the agent swarm\"\"\"\n",
    "    print(\"Welcome to the Agent Swarm Chat!\")\n",
    "    print(\"Type 'exit' or 'quit' to end the conversation.\")\n",
    "    print(\"Starting with Alice as the default agent.\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        # Check if user wants to exit\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Create a message with just the current user input\n",
    "        # The checkpointer will maintain the conversation state\n",
    "        current_message = [{\"role\": \"user\", \"content\": user_input}]\n",
    "        \n",
    "        # Invoke the agent swarm with just the new message\n",
    "        response = app.invoke(\n",
    "            {\"messages\": current_message},\n",
    "            config,\n",
    "        )\n",
    "        \n",
    "        # Extract and display the agent's response\n",
    "        formatted_response = format_agent_response(response)\n",
    "        print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa82b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b8f65a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
