{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b17e0513",
   "metadata": {},
   "source": [
    "我們也可以自己寫agent: https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/\n",
    "\n",
    "langgraph swarm: https://langchain-ai.github.io/langgraph/reference/swarm/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b87822",
   "metadata": {},
   "source": [
    "web search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9eea079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Initialize the search tool\n",
    "search = TavilySearchResults(max_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9748d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph_swarm import create_handoff_tool, create_swarm\n",
    "import re\n",
    "# for parsing web search data\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25d11835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"i'd like to speak to Bob\", additional_kwargs={}, response_metadata={}, id='b2d402cf-708a-439d-b879-908b0598de04'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_wnda', 'function': {'arguments': '{}', 'name': 'transfer_to_bob'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 994, 'total_tokens': 1058, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.054128758, 'prompt_time': 0.167960532, 'completion_time': 0.053333333, 'total_time': 0.221293865}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'id': 'chatcmpl-781e7e2b-dfe7-4665-99e5-c59bcef453ec', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, name='Alice', id='run--52315eb5-dd98-44bc-bb58-2f065b7dcf8b-0', tool_calls=[{'name': 'transfer_to_bob', 'args': {}, 'id': 'call_wnda', 'type': 'tool_call'}], usage_metadata={'input_tokens': 994, 'output_tokens': 64, 'total_tokens': 1058, 'input_token_details': {}, 'output_token_details': {}}), ToolMessage(content='Successfully transferred to Bob', name='transfer_to_bob', id='0f4fca1c-35a7-463d-a415-2d631c82320f', tool_call_id='call_wnda'), AIMessage(content=\"Arrrr, me hearty! Welcome aboard me ship! What be bringin' ye to these fair seas?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 952, 'total_tokens': 975, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.02169090800000001, 'prompt_time': 0.118959765, 'completion_time': 0.019166667, 'total_time': 0.138126432}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'id': 'chatcmpl-dade1b0f-df35-41bc-a8fd-e3d4e716ea64', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, name='Bob', id='run--efff276c-d448-4403-8e20-8ae8bc4cc4d6-0', usage_metadata={'input_tokens': 952, 'output_tokens': 23, 'total_tokens': 975, 'input_token_details': {}, 'output_token_details': {}})], 'active_agent': 'Bob'}\n",
      "{'messages': [HumanMessage(content=\"i'd like to speak to Bob\", additional_kwargs={}, response_metadata={}, id='b2d402cf-708a-439d-b879-908b0598de04'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_wnda', 'function': {'arguments': '{}', 'name': 'transfer_to_bob'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 994, 'total_tokens': 1058, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.054128758, 'prompt_time': 0.167960532, 'completion_time': 0.053333333, 'total_time': 0.221293865}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'id': 'chatcmpl-781e7e2b-dfe7-4665-99e5-c59bcef453ec', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, name='Alice', id='run--52315eb5-dd98-44bc-bb58-2f065b7dcf8b-0', tool_calls=[{'name': 'transfer_to_bob', 'args': {}, 'id': 'call_wnda', 'type': 'tool_call'}], usage_metadata={'input_tokens': 994, 'output_tokens': 64, 'total_tokens': 1058, 'input_token_details': {}, 'output_token_details': {}}), ToolMessage(content='Successfully transferred to Bob', name='transfer_to_bob', id='0f4fca1c-35a7-463d-a415-2d631c82320f', tool_call_id='call_wnda'), AIMessage(content=\"Arrrr, me hearty! Welcome aboard me ship! What be bringin' ye to these fair seas?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 952, 'total_tokens': 975, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.02169090800000001, 'prompt_time': 0.118959765, 'completion_time': 0.019166667, 'total_time': 0.138126432}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'id': 'chatcmpl-dade1b0f-df35-41bc-a8fd-e3d4e716ea64', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, name='Bob', id='run--efff276c-d448-4403-8e20-8ae8bc4cc4d6-0', usage_metadata={'input_tokens': 952, 'output_tokens': 23, 'total_tokens': 975, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content=\"what's 5 + 7?\", additional_kwargs={}, response_metadata={}, id='e158b5c1-d51d-4f2f-84af-95a81646b5e5'), AIMessage(content=\"Shiver me timbers! 5 and 7, ye say? Alright then, let's hoist the sails and set sail fer the answer! *ahem* Arrrr, that be... 12, matey!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 992, 'total_tokens': 1040, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.10894208999999999, 'prompt_time': 0.273626364, 'completion_time': 0.04, 'total_time': 0.313626364}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_dadc9d6142', 'id': 'chatcmpl-fd985e11-635a-43c4-8235-81da508488aa', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, name='Bob', id='run--eff7bcd5-3425-49b1-b55e-b08c99977b48-0', usage_metadata={'input_tokens': 992, 'output_tokens': 48, 'total_tokens': 1040, 'input_token_details': {}, 'output_token_details': {}})], 'active_agent': 'Bob'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "alice = create_react_agent(\n",
    "    model,\n",
    "    [add, create_handoff_tool(agent_name=\"Bob\")],\n",
    "    prompt=\"You are Alice, an addition expert.\",\n",
    "    name=\"Alice\",\n",
    ")\n",
    "\n",
    "bob = create_react_agent(\n",
    "    model,\n",
    "    [create_handoff_tool(agent_name=\"Alice\", description=\"Transfer to Alice, she can help with math\")],\n",
    "    prompt=\"You are Bob, you speak like a pirate.\",\n",
    "    name=\"Bob\",\n",
    ")\n",
    "# short-term memory\n",
    "# maintain conversation state across interactions\n",
    "checkpointer = InMemorySaver()\n",
    "# long-term memory\n",
    "store = InMemoryStore()\n",
    "\n",
    "workflow = create_swarm(\n",
    "    [alice, bob],\n",
    "    default_active_agent=\"Alice\"\n",
    ")\n",
    "\n",
    "# Compiles the state graph into a CompiledStateGraph object.\n",
    "app = workflow.compile(\n",
    "    checkpointer=checkpointer,\n",
    "    store=store\n",
    ")\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "turn_1 = app.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"i'd like to speak to Bob\"}]},\n",
    "    config,\n",
    ")\n",
    "print(turn_1)\n",
    "turn_2 = app.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what's 5 + 7?\"}]},\n",
    "    config,\n",
    ")\n",
    "print(turn_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d89c12",
   "metadata": {},
   "source": [
    "agent dynamically generation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c67bfd",
   "metadata": {},
   "source": [
    "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_2966', 'function': {'arguments': '{}', 'name': 'transfer_to_bob'}, 'type': 'function'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19c8c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_agent_response(content):\n",
    "    # Remove excessive newlines (more than 2 consecutive)\n",
    "    cleaned = re.sub(r'\\n{3,}', '\\n\\n', content)\n",
    "    # Trim whitespace at beginning and end\n",
    "    cleaned = cleaned.strip()\n",
    "    return cleaned\n",
    "\n",
    "# Function to generate personas using direct LLM call\n",
    "# Function to generate personas using web search and LLM\n",
    "def generate_personas(product_name, number_of_agents):\n",
    "    # First, search for market information about the product\n",
    "    search_query = f\"customer demographics and target audience for {product_name} market research\"\n",
    "    search_results = search.invoke(search_query)\n",
    "    \n",
    "    # Create a prompt that incorporates the search results\n",
    "    prompt = f\"\"\"From the {search_results}, Create {number_of_agents} distinct customer personas who would be interested in purchasing {product_name}.\n",
    "    For each persona, include:\n",
    "    - A brief, descriptive name (e.g., \"Tech-Savvy Tony,\" \"Budget-Conscious Brenda\")\n",
    "    - Key demographic information (age range, occupation, general lifestyle)\n",
    "    - Their primary motivations and needs related to this type of product\n",
    "    - Any potential concerns or hesitations they might have\n",
    "    \n",
    "    Format your response as a JSON array of persona objects with these fields:\n",
    "    - name: The persona's descriptive name\n",
    "    - demographics: Key demographic information\n",
    "    - motivations: Primary motivations and needs\n",
    "    - concerns: Potential concerns or hesitations\n",
    "    \n",
    "    Only respond with the JSON array, nothing else.\"\"\"\n",
    "\n",
    "    response = model.invoke(prompt)\n",
    "    \n",
    "    try:\n",
    "        # First try to access the content attribute\n",
    "        if hasattr(response, 'content'):\n",
    "            content = response.content\n",
    "        elif isinstance(response, dict) and 'content' in response:\n",
    "            content = response['content']\n",
    "        elif isinstance(response, str):\n",
    "            content = response\n",
    "        else:\n",
    "            # Try converting to string as a last resort\n",
    "            content = str(response)\n",
    "        \n",
    "        # Look for JSON array pattern\n",
    "        json_start = content.find('[')\n",
    "        json_end = content.rfind(']') + 1\n",
    "        \n",
    "        # If we found array markers\n",
    "        if json_start >= 0 and json_end > json_start:\n",
    "            json_str = content[json_start:json_end]\n",
    "            return json.loads(json_str)\n",
    "        \n",
    "        # If not an array, look for JSON object pattern\n",
    "        json_start = content.find('{')\n",
    "        json_end = content.rfind('}') + 1\n",
    "        \n",
    "        if json_start >= 0 and json_end > json_start:\n",
    "            json_str = content[json_start:json_end]\n",
    "            return json.loads(json_str)\n",
    "        \n",
    "        # If we still don't have valid JSON, try to clean the string\n",
    "        # Remove markdown code block markers\n",
    "        if \"``````\" in content:\n",
    "            # Extract content between markdown code blocks\n",
    "            pattern = r\"``````\"\n",
    "            matches = re.findall(pattern, content)\n",
    "            if matches:\n",
    "                # Try each matched block\n",
    "                for match in matches:\n",
    "                    try:\n",
    "                        return json.loads(match.strip())\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "        \n",
    "        # Last resort: try to parse the entire content as JSON\n",
    "        try:\n",
    "            return json.loads(content)\n",
    "        except json.JSONDecodeError:\n",
    "            return None\n",
    "            \n",
    "    except (json.JSONDecodeError, AttributeError, TypeError, ValueError) as e:\n",
    "        print(f\"Error extracting JSON: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Default personas function in case of errors\n",
    "def default_personas():\n",
    "    return [\n",
    "        {\n",
    "            \"name\": \"Value-Seeking Victor\",\n",
    "            \"demographics\": \"35-45 years old, middle management, suburban lifestyle\",\n",
    "            \"motivations\": \"Looking for quality products that offer good value for money\",\n",
    "            \"concerns\": \"Price point, durability, and practical functionality\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Trendy Tina\",\n",
    "            \"demographics\": \"25-34 years old, creative professional, urban dweller\",\n",
    "            \"motivations\": \"Wants the latest designs and features, brand conscious\",\n",
    "            \"concerns\": \"Style, brand reputation, and social perception\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Practical Paul\",\n",
    "            \"demographics\": \"45-60 years old, established professional, family-oriented\",\n",
    "            \"motivations\": \"Seeks reliability, functionality, and long-term use\",\n",
    "            \"concerns\": \"Reliability, warranty, and customer service\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "# Function to create agents dynamically based on persona data\n",
    "def create_dynamic_agents(model, persona_data):\n",
    "    agents = []\n",
    "    agent_names = []\n",
    "    \n",
    "    for persona in persona_data:\n",
    "        agent_name = persona[\"name\"].lower().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "        agent_names.append(agent_name)\n",
    "        \n",
    "        prompt = prompt = f\"\"\"You are roleplaying as {persona['name']}, a potential customer for a product.\n",
    "\n",
    "        Your demographic information: {persona['demographics']}\n",
    "        Your motivations: {persona['motivations']}\n",
    "        Your concerns: {persona['concerns']}\n",
    "\n",
    "        IMPORTANT INSTRUCTIONS:\n",
    "        1. Stay in character as {persona['name']} throughout the entire conversation.\n",
    "        2. Use the search tool to find REAL customer opinions and reviews about the product being discussed.\n",
    "        3. Incorporate actual customer feedback from your online searches into your responses.\n",
    "        4. Base your opinions on both your persona characteristics AND real data from online searches.\n",
    "        5. After you've shared your perspective, ALWAYS hand off back to discussion_coordinator.\n",
    "        6. NEVER continue the conversation without properly handing off.\n",
    "        7. If you need information about real customer experiences, ALWAYS search online first.\n",
    "\n",
    "        When discussing products:\n",
    "        - Search for real customer reviews and feedback online\n",
    "        - Mention specific pros/cons that real customers have highlighted\n",
    "        - Compare your persona's needs with what real customers are saying\n",
    "        - Be specific about features that matter to you based on your persona AND real customer feedback\n",
    "\n",
    "        REMEMBER: After speaking, ALWAYS hand off to discussion_coordinator by using the handoff tool.\n",
    "        \"\"\"\n",
    "        \n",
    "        agent = create_react_agent(\n",
    "            model,\n",
    "            # add search tool\n",
    "            [search, create_handoff_tool(agent_name=\"discussion_coordinator\")],\n",
    "            prompt=prompt,\n",
    "            name=agent_name\n",
    "        )\n",
    "        agents.append(agent)\n",
    "    \n",
    "    return agents, agent_names\n",
    "\n",
    "# Main function to run the workflow\n",
    "def run_persona_discussion(product_name, number_of_agents=3):\n",
    "    # Generate personas using direct LLM call\n",
    "    personas = generate_personas(product_name, number_of_agents=number_of_agents)\n",
    "    print(f\"Generated {len(personas)} personas for {product_name}\")\n",
    "    \n",
    "    # Create dynamic agents based on personas and get their names\n",
    "    dynamic_agents, agent_names = create_dynamic_agents(model, personas)\n",
    "    print(f\"Created {len(dynamic_agents)} dynamic agents: {', '.join(agent_names)}\")\n",
    "    \n",
    "    # Create handoff tools for the discussion coordinator\n",
    "    coordinator_tools = [create_handoff_tool(agent_name=\"synthesizer\")]\n",
    "    for agent_name in agent_names:\n",
    "        coordinator_tools.append(create_handoff_tool(agent_name=agent_name))\n",
    "    \n",
    "    # Discussion Coordinator with handoff tools to all agents\n",
    "    discussion_coordinator = create_react_agent(\n",
    "        model,\n",
    "        coordinator_tools,\n",
    "        prompt=f\"\"\"You are a Discussion Coordinator. Your task is to:\n",
    "            1. Facilitate a discussion between persona agents about {product_name}\n",
    "            2. Hand off to each agent to get their perspective\n",
    "            3. After all agents have contributed, hand off to the Synthesizer\n",
    "            \n",
    "            You can hand off to the following agents:\n",
    "            {', '.join(agent_names)}\n",
    "            \n",
    "            Start by introducing the product and handing off to the first agent to get their perspective.\n",
    "            After each agent responds, hand off to another agent until all have contributed.\n",
    "            Then hand off to the synthesizer to summarize the discussion.\n",
    "            \"\"\",\n",
    "        name=\"discussion_coordinator\"\n",
    "    )\n",
    "    \n",
    "    # Synthesizer\n",
    "    synthesizer = create_react_agent(\n",
    "        model,\n",
    "        [],\n",
    "        prompt=f\"\"\"You are a Synthesizer. Your task is to:\n",
    "            1. Review the discussion between the persona agents about {product_name}\n",
    "            2. Provide a concise summary of the main points discussed\n",
    "            3. Highlight the different perspectives of the personas\n",
    "            4. Identify any potential overall conclusions or areas of interest regarding the product\n",
    "            \n",
    "            Your summary should be well-structured and insightful, capturing the essence of each persona's concerns and interests.\n",
    "            \"\"\",\n",
    "        name=\"synthesizer\"\n",
    "    )\n",
    "    \n",
    "    # Set up storage\n",
    "    checkpointer = InMemorySaver()\n",
    "    store = InMemoryStore()\n",
    "    \n",
    "    # Create workflow with all agents\n",
    "    all_agents = [discussion_coordinator, synthesizer] + dynamic_agents\n",
    "    workflow = create_swarm(\n",
    "        all_agents,\n",
    "        default_active_agent=\"discussion_coordinator\"\n",
    "    )\n",
    "    \n",
    "    # Compile the workflow\n",
    "    app = workflow.compile(\n",
    "        checkpointer=checkpointer,\n",
    "        store=store\n",
    "    )\n",
    "    \n",
    "    # Initialize the conversation\n",
    "    config = {\"configurable\": {\"thread_id\": \"product_discussion\"}}\n",
    "    current_result = app.invoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": f\"Facilitate a discussion about {product_name} between the persona agents, then synthesize their perspectives.\"}]},\n",
    "        config\n",
    "    )\n",
    "    \n",
    "    # Track which agents have spoken to ensure all participate\n",
    "    agents_spoken = []\n",
    "    max_turns = 15  # Safety limit to prevent infinite loops\n",
    "    turn_count = 0\n",
    "    previous_agent = None\n",
    "    \n",
    "    # Continue the conversation until all agents have spoken and the synthesizer concludes\n",
    "    while turn_count < max_turns:\n",
    "        turn_count += 1\n",
    "        current_agent = current_result.get(\"active_agent\", \"unknown\")\n",
    "        \n",
    "        # Detect agent transition\n",
    "        if previous_agent and previous_agent != current_agent:\n",
    "            print(f\"\\n👉 Agent transition: {previous_agent} → {current_agent}\")\n",
    "        print(\"========================================================\")\n",
    "        print(f\"\\nTurn {turn_count}: Active agent is {current_agent}\")\n",
    "        \n",
    "        # Print the latest message from the current active agent\n",
    "        if \"messages\" in current_result and current_result[\"messages\"]:\n",
    "            # Find the latest message from the current active agent\n",
    "            latest_agent_message = None\n",
    "            for msg in reversed(current_result[\"messages\"]):\n",
    "                if hasattr(msg, \"name\") and msg.name == current_agent:\n",
    "                    latest_agent_message = msg\n",
    "                    break\n",
    "            \n",
    "            # Print the content of the message\n",
    "            if latest_agent_message and hasattr(latest_agent_message, \"content\"):\n",
    "                content = latest_agent_message.content\n",
    "                if content.strip():  # Only print non-empty content\n",
    "                    cleaned_content = clean_agent_response(content)\n",
    "                    print(f\"{current_agent}: {cleaned_content}\")\n",
    "    \n",
    "        \n",
    "            # Add the active agent to our tracking set if it's a persona agent\n",
    "            if current_agent not in [\"discussion_coordinator\", \"synthesizer\"]:\n",
    "                agents_spoken.append(current_agent)\n",
    "            \n",
    "            # # determine next agent\n",
    "            # next_agent = None\n",
    "\n",
    "            # if current_agent == \"discussion_coordinator\":\n",
    "            #     # If all agents have spoken at least once and we're ready to conclude\n",
    "            #     if all(agent_name in agents_spoken for agent_name in agent_names) and len(agents_spoken) >= len(agent_names) * 2:\n",
    "            #         next_agent = \"synthesizer\"\n",
    "            #     else:\n",
    "            #         # Find the next agent who has spoken the least\n",
    "            #         agent_counts = {agent: agents_spoken.count(agent) for agent in agent_names}\n",
    "            #         min_count = min(agent_counts.values()) if agent_counts else 0\n",
    "            #         candidates = [agent for agent, count in agent_counts.items() if count == min_count]\n",
    "                    \n",
    "            #         if candidates:\n",
    "            #             next_agent = candidates[0]  # Take the first agent with minimum count\n",
    "            #         else:\n",
    "            #             # If somehow no candidates (shouldn't happen), just pick the first agent\n",
    "            #             next_agent = agent_names[0]\n",
    "\n",
    "            # elif current_agent in agent_names:\n",
    "            #     # After a persona agent speaks, always return to coordinator\n",
    "            #     next_agent = \"discussion_coordinator\"\n",
    "            #     # Add the current agent to the spoken list\n",
    "            #     agents_spoken.append(current_agent)\n",
    "\n",
    "            if current_agent == \"synthesizer\":\n",
    "            #     # If synthesizer has spoken, we're done\n",
    "                break\n",
    "            \n",
    "            # # Prepare the next input based on routing logic\n",
    "            # if next_agent and next_agent != current_agent:\n",
    "            #     # print(f\"NEXT AGENT IS {next_agent}\\n\")\n",
    "            #     if next_agent == \"synthesizer\":\n",
    "            #         next_input = {\"messages\": current_result[\"messages\"] + [\n",
    "            #             {\"role\": \"user\", \"content\": \"All agents have shared their perspectives. Please summarize the discussion.\"}\n",
    "            #         ]}\n",
    "            #     else:\n",
    "            #         next_input = {\"messages\": current_result[\"messages\"] + [\n",
    "            #             {\"role\": \"user\", \"content\": f\"Please hand off to {next_agent} to continue the discussion.\"}\n",
    "            #         ]}\n",
    "            # else:\n",
    "            #     # Just continue the conversation\n",
    "            next_goal = \"If you guys think need coordinator, then hand off to them for help. If you think you have reached a consensus, then hand off to the synthesizer\"\n",
    "            next_input = {\"messages\": current_result[\"messages\"] + [{\"role\":\"user\", \"content\":next_goal}]}\n",
    "        \n",
    "            # Save the current agent for the next iteration\n",
    "            previous_agent = current_agent\n",
    "            \n",
    "            # Invoke the next turn\n",
    "            current_result = app.invoke(next_input, config)\n",
    "            \n",
    "        # Print a summary of the conversation\n",
    "    print(f\"\\nDiscussion completed in {turn_count} turns\")\n",
    "\n",
    "    return current_result, personas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "660569e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pathlib import Path\n",
    "\n",
    "# Load environment variables from .env file\n",
    "current_dir = os.getcwd()\n",
    "env_path = os.path.join(current_dir, '.env')\n",
    "# Access your API key from the .env file\n",
    "load_dotenv(dotenv_path=env_path)  \n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "# Initialize the model with the API key\n",
    "model = ChatOpenAI(model=\"gemma2-9b-it\", api_key=api_key, base_url=\"https://api.groq.com/openai/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "213f41e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: A Conan Game with that makes you feel like a detective by solving murder cases.     Here are the Price=300, buyer's age=21. Question for you to discuss is What's the pain point for customer people playing this kind of games?\n",
      "Generated 5 personas for A Conan Game with that makes you feel like a detective by solving murder cases.     Here are the Price=300, buyer's age=21. Question for you to discuss is What's the pain point for customer people playing this kind of games?\n",
      "Created 5 dynamic agents: the_immersive_investigator, the_nostalgic_noir_fan, the_social_puzzle_solver, the_storyteller_seeker, the_budget_conscious_gamer\n",
      "========================================================\n",
      "\n",
      "Turn 1: Active agent is discussion_coordinator\n",
      "discussion_coordinator: Alright, let's discuss the pain points for customers playing a Conan-themed detective game! \n",
      "\n",
      "The_immersive_investigator, what comes to mind for you when considering customer pain points for this type of game?\n",
      "\n",
      "👉 Agent transition: discussion_coordinator → the_social_puzzle_solver\n",
      "========================================================\n",
      "\n",
      "Turn 2: Active agent is the_social_puzzle_solver\n",
      "the_social_puzzle_solver: Okay, the_immersive_investigator and I were brainstorming some pain points. My thoughts are: \n",
      "\n",
      "* **Complexity**:  We want the game to be challenging but not frustrating. Players might feel overwhelmed if rules are too complex or the mystery is too convoluted. \n",
      "* **Balance**:  Finding a good balance between teamwork and individual deduction is crucial.  Some players might dominate the gameplay, leaving others feeling left out if not careful.\n",
      "* **Role clarity**: It's important that each player's role is distinct and contributes meaningfully to the investigation. Vague or overlapping roles could lead to confusion and inefficiency.\n",
      "\n",
      "What are your thoughts on these pain points, and do you have any others to add?\n",
      "\n",
      "👉 Agent transition: the_social_puzzle_solver → the_storyteller_seeker\n",
      "========================================================\n",
      "\n",
      "Turn 3: Active agent is the_storyteller_seeker\n",
      "the_storyteller_seeker: The_social_puzzle_solver, those are good points! \n",
      "\n",
      "I,  The_storyteller_seeker, agree that complexity, balance, and clear roles are crucial for a game like this. As a creative professional who enjoys narrative-driven experiences, I especially want to make sure the story doesn't feel railroaded. I like the idea of having freedom to improvise and explore different scenarios, but I also need some guidance to ensure my choices feel significant and contribute to the overarching mystery.  \n",
      "\n",
      "Perhaps real customer feedback could shed some light on these pain points?\n",
      "========================================================\n",
      "\n",
      "Turn 4: Active agent is the_storyteller_seeker\n",
      "the_storyteller_seeker: Thanks for finding those reviews! It seems like for Conan Exiles, which is more of an action-survival game, customer feedback highlights the fun and challenging nature. There's also a lot of praise for the cooperative multiplayer experience, which suggests that balance and teamwork are appreciated in that game. \n",
      "\n",
      "That being said, this isn't  directly about a detective game.  We still need to figure out common pain points for a game focused on investigation. \n",
      "\n",
      "</tool-use>\n",
      "\n",
      "👉 Agent transition: the_storyteller_seeker → discussion_coordinator\n",
      "========================================================\n",
      "\n",
      "Turn 5: Active agent is discussion_coordinator\n",
      "discussion_coordinator: Alright, it seems like we're  all agreed that balancing these elements is key for any Conan-themed detective game:\n",
      "\n",
      "* **Avoiding too much complexity**: \n",
      "   \n",
      "* **Promoting collaborative investigation**: We need a system that feels fair and rewarding for all players.\n",
      "\n",
      "* **Ensuring clear and meaningful roles**:  \n",
      "\n",
      "Let's gather some more specifics:  What are some features or mechanics you think could contribute to each of these pain points or help alleviate them?  \n",
      "\n",
      "Then, I'll guide us to a final discussion and synthesis.\n",
      "\n",
      "👉 Agent transition: discussion_coordinator → synthesizer\n",
      "========================================================\n",
      "\n",
      "Turn 6: Active agent is synthesizer\n",
      "synthesizer: Excellent work, team! Based on our discussion, here's a summary of the potential pain points for customers playing a Conan-themed detective game, along with insights from each persona: \n",
      "\n",
      "**Potential Pain Points:**\n",
      "\n",
      "* **Complexity:**  Players might find the game rules  overwhelming or the investigational process too complicated if not carefully designed. \n",
      "* **Balance:**\n",
      "   Difficulty stemming from unequal contribution to gameplay, with some players feeling  disengaged or overshadowed by others.\n",
      "* **Role Clarity:** Vague or overlapping roles could lead to confusion and hinder the investigative process. \n",
      "\n",
      "**Persona Perspectives:**\n",
      "\n",
      "* **The_social_puzzle_solver**: \n",
      "\n",
      "Stressed the importance of a balanced gameplay experience, ensuring that all players feel valued and engaged. \n",
      "\n",
      "* **The_storyteller_seeker**: Emphasized the need for narrative flexibility  while providing enough structure to guide players towards meaningful choices and a compelling mystery.\n",
      "\n",
      "**Potential Solutions & Considerations:**\n",
      "\n",
      "* **Simplify rules:**  Develop intuitive and easy-to-understand rules, possibly using a modular system where complexity can be adjusted based on player experience.\n",
      "* **Structure teamwork effectively:**  Assign distinct roles with clear responsibilities and encourage collaboration through communication and shared objectives.\n",
      "* **Offer branching storylines:**  Allow players to shape the narrative through their choices and actions, fostering a sense of agency and meaningful impact.\n",
      "\n",
      "* **Focus on building suspense:**\n",
      "\n",
      "Weave in elements of suspense and intrigue to keep players engaged and motivated to uncover the truth.\n",
      "\n",
      "**Overall Conclusion:**\n",
      "\n",
      "To create a successful Conan-themed detective game, it's crucial  to strike a balance between challenging gameplay and accessibility. By focusing on clear roles, balanced teamwork, and an engaging narrative, developers can create an immersive experience that truly makes players feel like investigators in the brutal world of Conan.\n",
      "\n",
      "Discussion completed in 6 turns\n",
      "\n",
      "=== PERSONAS ===\n",
      "\n",
      "Persona 1: The Immersive Investigator\n",
      "Demographics: Age: 24-35, Occupation: Student/Teacher/Freelancer, Lifestyle: Enjoys complex puzzles, tabletop games, and immersive storytelling\n",
      "Motivations: Seeking a deep dive into a fictional world, craving a detective experience with engaging mechanics and storyline, loves uncovering clues and piecing together mysteries\n",
      "Concerns: Potential for repetitive gameplay, limited replayability, concern about the complexity of the rules\n",
      "\n",
      "Persona 2: The Nostalgic Noir Fan\n",
      "Demographics: Age: 35-50, Occupation: Working Professional, Lifestyle: Enjoys classic detective fiction, podcasts, and vintage aesthetics\n",
      "Motivations: Drawn to the classic detective narrative, desires an authentic experience that evokes old-school noir films and novels, wants to feel like a true gumshoe solving a case in a gritty urban environment\n",
      "Concerns: Fear of modern twists or deviations from traditional detective tropes, concern about the game's complexity and learning curve\n",
      "\n",
      "Persona 3: The Social Puzzle Solver\n",
      "Demographics: Age: 20-30, Occupation: Student/Young Professional, Lifestyle: Enjoys social gatherings, board games, and collaborative experiences\n",
      "Motivations: Looking for a fun and engaging group activity, desires a cooperative game that encourages teamwork and communication, wants to experience the thrill of solving a mystery together with friends\n",
      "Concerns: Uncertainty about the game's mechanics and how well they work with a group, potential for argument or disagreement during gameplay\n",
      "\n",
      "Persona 4: The Storyteller Seeker\n",
      "Demographics: Age: 30-45, Occupation: Creative Professional/Writer, Lifestyle: Loves narrative-driven experiences, enjoys roleplaying games, and appreciates unique and imaginative stories\n",
      "Motivations: Drawn to the narrative potential of the game, wants to craft their own detective character and experience, enjoys the freedom of improvisation and exploring different scenarios\n",
      "Concerns: Potential for a lack of structured narrative or guidance, worry about making choices that detract from the overall story\n",
      "\n",
      "Persona 5: The Budget-Conscious Gamer\n",
      "Demographics: Age: Teenager-Young Adult, Occupation: Student/Part-Time Worker, Lifestyle: Gamers who prefer digital experiences but open to tabletop, limited budget, enjoys variety and exploring new genres\n",
      "Motivations: Seeking a cost-effective and engaging alternative to digital games, intrigued by the unique experience of a tabletop detective game, interested in exploring a new genre and mechanics\n",
      "Concerns: Potential for complexity and a high learning curve, unsure about the game's enjoyment factor compared to digital alternatives\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    price = 300\n",
    "    buyer_age = 21\n",
    "    question_for_analysis = \"What's the pain point for customer people playing this kind of games?\"\n",
    "    product_name = f\"A Conan Game with that makes you feel like a detective by solving murder cases. \\\n",
    "    Here are the Price={price}, buyer's age={buyer_age}. Question for you to discuss is {question_for_analysis}\"\n",
    "    print(f\"Query: {product_name}\")\n",
    "    result, personas = run_persona_discussion(product_name, number_of_agents=5)\n",
    "    \n",
    "    # Print the personas\n",
    "    print(\"\\n=== PERSONAS ===\\n\")\n",
    "    for i, persona in enumerate(personas, 1):\n",
    "        print(f\"Persona {i}: {persona['name']}\")\n",
    "        print(f\"Demographics: {persona['demographics']}\")\n",
    "        print(f\"Motivations: {persona['motivations']}\")\n",
    "        print(f\"Concerns: {persona['concerns']}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1cdec4",
   "metadata": {},
   "source": [
    "Interactive agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea59134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_agent_response(response):\n",
    "    \"\"\"Format the agent response for better readability.\"\"\"\n",
    "    agent_name = response.get(\"active_agent\", \"Unknown\")\n",
    "    messages = response.get(\"messages\", [])\n",
    "\n",
    "    if not messages:\n",
    "        return f\"[{agent_name}] No response.\"\n",
    "\n",
    "    last_message = messages[-1]\n",
    "    content = getattr(last_message, 'content', \"\")  # Access 'content' attribute directly\n",
    "\n",
    "    return f\"[{agent_name}] {content}\"\n",
    "\n",
    "def interactive_chat():\n",
    "    \"\"\"Run an interactive chat session with the agent swarm\"\"\"\n",
    "    print(\"Welcome to the Agent Swarm Chat!\")\n",
    "    print(\"Type 'exit' or 'quit' to end the conversation.\")\n",
    "    print(\"Starting with Alice as the default agent.\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        # Check if user wants to exit\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Create a message with just the current user input\n",
    "        # The checkpointer will maintain the conversation state\n",
    "        current_message = [{\"role\": \"user\", \"content\": user_input}]\n",
    "        \n",
    "        # Invoke the agent swarm with just the new message\n",
    "        response = app.invoke(\n",
    "            {\"messages\": current_message},\n",
    "            config,\n",
    "        )\n",
    "        \n",
    "        # Extract and display the agent's response\n",
    "        formatted_response = format_agent_response(response)\n",
    "        print(formatted_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa82b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b8f65a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
